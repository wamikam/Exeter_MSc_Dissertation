{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general python imports and jupyter configuration\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "!pip install tensorflow==1.14\n",
    "import random\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_curve, auc, average_precision_score\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data into dataframe\n",
    "df = pd.read_csv(\"steam-200k.csv\", header=None, index_col=None, names=['UserID', 'Game', 'Action', 'Hours', 'Other'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "df['Hours_Played'] = df['Hours'].astype('float32')\n",
    "\n",
    "df.loc[(df['Action'] == 'purchase') & (df['Hours'] == 1.0), 'Hours_Played'] = 0\n",
    "\n",
    "df.UserID = df.UserID.astype('int')\n",
    "df = df.sort_values(['UserID', 'Game', 'Hours_Played'])\n",
    "\n",
    "clean_df = df.drop_duplicates(['UserID', 'Game'], keep = 'last').drop(['Action', 'Hours', 'Other'], axis = 1)\n",
    "\n",
    "# every transaction is represented by only one record now\n",
    "clean_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = len(clean_df.UserID.unique())\n",
    "n_games = len(clean_df.Game.unique())\n",
    "\n",
    "print('There are {0} users and {1} games in the data'.format(n_users, n_games))\n",
    "sparsity = clean_df.shape[0] / float(n_users * n_games)\n",
    "print('{:.2%} of the user-item matrix is filled'.format(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "!pip install tensorflow==2.2\n",
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "import random\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_curve, auc, average_precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_counter = Counter()\n",
    "for user in clean_df.UserID.tolist():\n",
    "    user_counter[user] +=1\n",
    "\n",
    "game_counter = Counter()\n",
    "for game in clean_df.Game.tolist():\n",
    "    game_counter[game] += 1\n",
    "\n",
    "user2idx = {user: i for i, user in enumerate(clean_df.UserID.unique())}\n",
    "idx2user = {i: user for user, i in user2idx.items()}\n",
    "\n",
    "game2idx = {game: i for i, game in enumerate(clean_df.Game.unique())}\n",
    "idx2game = {i: game for game, i in game2idx.items()}\n",
    "\n",
    "user_idx = clean_df['UserID'].apply(lambda x: user2idx[x]).values\n",
    "game_idx = clean_df['gameIdx'] = clean_df['Game'].apply(lambda x: game2idx[x]).values\n",
    "hours = clean_df['Hours_Played'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User X game matrix formation\n",
    "zero_matrix = np.zeros(shape = (n_users, n_games)) # Create a zero matrix\n",
    "user_game_pref = zero_matrix.copy()\n",
    "user_game_pref[user_idx, game_idx] = 1 # Fill preference matrix\n",
    "\n",
    "user_game_interactions = zero_matrix.copy()\n",
    "# Confidence matrix\n",
    "user_game_interactions[user_idx, game_idx] = hours + 1 \n",
    "\n",
    "k = 5\n",
    "\n",
    "# Count the number of purchases for each user\n",
    "purchase_counts = np.apply_along_axis(np.bincount, 1, user_game_pref.astype(int))\n",
    "\n",
    "#find the users who purchase 2 * k games\n",
    "buyers_idx = np.where(purchase_counts[:, 1] >= 2 * k)[0] \n",
    "\n",
    "print('{0} users bought {1} or more games'.format(len(buyers_idx), 2 * k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "\n",
    "test_frac = 0.2 # Let's save 10% of the data for validation and 10% for testing.\n",
    "test_users_idx = np.random.choice(buyers_idx,\n",
    "                                  size = int(np.ceil(len(buyers_idx) * test_frac)),\n",
    "                                  replace = False)\n",
    "val_users_idx = test_users_idx[:int(len(test_users_idx) / 2)]\n",
    "test_users_idx = test_users_idx[int(len(test_users_idx) / 2):]\n",
    "\n",
    "def data_process(dat, train, test, user_idx, k):\n",
    "    for user in user_idx:\n",
    "        purchases = np.where(dat[user, :] == 1)[0]\n",
    "        mask = np.random.choice(purchases, size = k, replace = False)\n",
    "        \n",
    "        train[user, mask] = 0\n",
    "        test[user, mask] = dat[user, mask]\n",
    "    return train, test\n",
    "\n",
    "train_matrix = user_game_pref.copy()\n",
    "test_matrix = zero_matrix.copy()\n",
    "val_matrix = zero_matrix.copy()\n",
    "\n",
    "# Mask the train matrix and create the validation and test matrices\n",
    "train_matrix, val_matrix = data_process(user_game_pref, train_matrix, val_matrix, val_users_idx, k)\n",
    "train_matrix, test_matrix = data_process(user_game_pref, train_matrix, test_matrix, test_users_idx, k)\n",
    "\n",
    "test_matrix[test_users_idx[0], test_matrix[test_users_idx[0], :].nonzero()[0]]\n",
    "\n",
    "train_matrix[test_users_idx[0], test_matrix[test_users_idx[0], :].nonzero()[0]]\n",
    "\n",
    "ops.reset_default_graph() # Create a new graphs\n",
    "\n",
    "pref = tf.placeholder(tf.float32, (n_users, n_games))  # Here's the preference matrix\n",
    "interactions =tf.placeholder(tf.float32, (n_users, n_games)) # Here's the hours played matrix\n",
    "users_idx = tf.placeholder(tf.int32, (None))\n",
    "\n",
    "n_features = 30 \n",
    "\n",
    "# The X matrix represents the user latent preferences with a shape of user x latent features\n",
    "X = tf.Variable(tf.truncated_normal([n_users, n_features], mean = 0, stddev = 0.05))\n",
    "\n",
    "# The Y matrix represents the game latent features with a shape of game x latent features\n",
    "Y = tf.Variable(tf.truncated_normal([n_games, n_features], mean = 0, stddev = 0.05))\n",
    "\n",
    "# Here's the initilization of the confidence parameter\n",
    "conf_alpha = tf.Variable(tf.random_uniform([1], 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Biases\n",
    "#user bias\n",
    "user_bias = tf.Variable(tf.truncated_normal([n_users, 1], stddev = 0.2))\n",
    "\n",
    "# Concatenate the vector to the user matrix\n",
    "X_plus_bias = tf.concat([X, \n",
    "                         #tf.convert_to_tensor(user_bias, dtype = tf.float32),\n",
    "                         user_bias,\n",
    "                         tf.ones((n_users, 1), dtype = tf.float32)], axis = 1)\n",
    "\n",
    "# game bias\n",
    "item_bias = tf.Variable(tf.truncated_normal([n_games, 1], stddev = 0.2))\n",
    "\n",
    "# Cocatenate the vector to the game matrix\n",
    "Y_plus_bias = tf.concat([Y, \n",
    "                         tf.ones((n_games, 1), dtype = tf.float32),\n",
    "                         item_bias],\n",
    "                         axis = 1)\n",
    "\n",
    "pred_pref = tf.matmul(X_plus_bias, Y_plus_bias, transpose_b=True)\n",
    "\n",
    "# Construct the confidence matrix with the hours played and alpha paramter\n",
    "conf = 1 + conf_alpha * interactions\n",
    "\n",
    "cost = tf.reduce_sum(tf.multiply(conf, tf.square(tf.subtract(pref, pred_pref))))\n",
    "l2_sqr = tf.nn.l2_loss(X) + tf.nn.l2_loss(Y) + tf.nn.l2_loss(user_bias) + tf.nn.l2_loss(item_bias)\n",
    "lambda_c = 0.01\n",
    "loss = cost + lambda_c * l2_sqr\n",
    "\n",
    "lr = 0.05\n",
    "optimize = tf.train.AdagradOptimizer(learning_rate = lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function that helps to calculate the top k precision \n",
    "def top_k_precision(pred, mat, k, user_idx):\n",
    "    precisions = []\n",
    "    \n",
    "    for user in user_idx:\n",
    "        rec = np.argsort(-pred[user, :]) # Found the top recommendation from the predictions\n",
    "        \n",
    "        top_k = rec[:k]\n",
    "        labels = mat[user, :].nonzero()[0]\n",
    "        \n",
    "        precision = len(set(top_k) & set(labels)) / float(k) # Calculate the precisions from actual labels\n",
    "        precisions.append(precision)\n",
    "    return np.mean(precisions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 100\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        sess.run(optimize, feed_dict = {pref: train_matrix,\n",
    "                                        interactions: user_game_interactions})\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            mod_loss = sess.run(loss, feed_dict = {pref: train_matrix,\n",
    "                                                   interactions: user_game_interactions})            \n",
    "            mod_pred = pred_pref.eval()\n",
    "            train_precision = top_k_precision(mod_pred, train_matrix, k, val_users_idx)\n",
    "            val_precision = top_k_precision(mod_pred, val_matrix, k, val_users_idx)\n",
    "            print('Iterations {0}...'.format(i),\n",
    "                  'Training Loss {:.2f}...'.format(mod_loss),\n",
    "                  'Train Precision {:.3f}...'.format(train_precision),\n",
    "                  'Val Precision {:.3f}'.format(val_precision)\n",
    "                )\n",
    "\n",
    "    rec = pred_pref.eval()\n",
    "    test_precision = top_k_precision(rec, test_matrix, k, test_users_idx)\n",
    "    print('\\n')\n",
    "    print('Test Precision{:.3f}'.format(test_precision))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the recommendation System\n",
    "n_examples = 30\n",
    "users = np.random.choice(test_users_idx, size = n_examples, replace = False)\n",
    "rec_games = np.argsort(-rec)\n",
    "\n",
    "for user in users:\n",
    "    print('User #{0} recommendations ...'.format(idx2user[user]))\n",
    "    purchase_history = np.where(train_matrix[user, :] != 0)[0]\n",
    "    recommendations = rec_games[user, :]\n",
    "\n",
    "    \n",
    "    new_recommendations = recommendations[~np.in1d(recommendations, purchase_history)][:k]\n",
    "    \n",
    "    print('Recommendations')\n",
    "    print(', '.join([idx2game[game] for game in new_recommendations]))\n",
    "    print('\\n')\n",
    "    print('Actual purchases')\n",
    "    print(', '.join([idx2game[game] for game in np.where(test_matrix[user, :] != 0)[0]]))\n",
    "    print('\\n')\n",
    "    print('Precision of {0}'.format(len(set(new_recommendations) & set(np.where(test_matrix[user, :] != 0)[0])) / float(k)))\n",
    "    print('--------------------------------------')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
