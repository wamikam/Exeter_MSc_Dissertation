{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "!pip install image\n",
    "import image\n",
    "import operator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time, pickle, pandas\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D ,Conv2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras import backend\n",
    "from keras import optimizers\n",
    "from keras import applications\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring the no of classes for the category\n",
    "nb_classes = 5\n",
    "class_name = {\n",
    "    0: 'Checked',\n",
    "    1: 'Floral',\n",
    "    2: 'Graphic',\n",
    "    3: 'Plain',\n",
    "    4: 'Striped'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(X, y, prediction=-1):\n",
    "    im = X\n",
    "    plt.imshow(im)\n",
    "    if prediction >= 0:\n",
    "        plt.title(\"Class = %s, Predict = %s\" % (class_name[y], class_name[prediction]))\n",
    "    else:\n",
    "        plt.title(\"Class = %s\" % (class_name[y]))\n",
    "\n",
    "    plt.axis('on')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'C:/Users/Wamika/Desktop/Dissertation/Images Fashion Clothing/Images/Train'\n",
    "validation_data_dir = 'C:/Users/Wamika/Desktop/Dissertation/Images Fashion Clothing/Images/Validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255        \n",
    "        )\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=50,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=50,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = 8782 \n",
    "nb_validation_samples = 2016\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "for X_batch, Y_batch in train_generator:\n",
    "    for i in range(5):\n",
    "        show_sample(X_batch[i, :, :, :], np.argmax(Y_batch[i]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg16(framework='tf'):\n",
    "\n",
    "    if framework == 'th':\n",
    "        # build the VGG16 network in Theano weight ordering mode\n",
    "        backend.set_image_dim_ordering('th')\n",
    "    else:\n",
    "        # build the VGG16 network in Tensorflow weight ordering mode\n",
    "        backend.set_image_dim_ordering('tf')\n",
    "        \n",
    "    model = Sequential()\n",
    "    if framework == 'th':\n",
    "        model.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\n",
    "    else:\n",
    "        model.add(ZeroPadding2D((1, 1), input_shape=(img_width, img_height, 3)))\n",
    "        \n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    return model\n",
    "\n",
    "weights_path = 'vgg16_weights.h5'\n",
    "th_model = build_vgg16('th')\n",
    "\n",
    "assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\n",
    "f = h5py.File(weights_path)\n",
    "for k in range(f.attrs['nb_layers']):\n",
    "    if k >= len(th_model.layers):\n",
    "        # we don't look at the last (fully-connected) layers in the savefile\n",
    "        break\n",
    "    g = f['layer_{}'.format(k)]\n",
    "    weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "    th_model.layers[k].set_weights(weights)\n",
    "f.close()\n",
    "print('Model loaded.')\n",
    "\n",
    "tf_model = build_vgg16('tf')\n",
    "\n",
    "for th_layer, tf_layer in zip(th_model.layers, tf_model.layers):\n",
    "    if th_layer.__class__.__name__ == 'Convolution2D':\n",
    "      kernel, bias = th_layer.get_weights()\n",
    "      kernel = np.transpose(kernel, (2, 3, 1, 0))\n",
    "      tf_layer.set_weights([kernel, bias])\n",
    "    else:\n",
    "      tf_layer.set_weights(tf_layer.get_weights())\n",
    "    \n",
    "top_model = Sequential()\n",
    "print (Flatten(input_shape=tf_model.output_shape[1:]))\n",
    "top_model.add(Flatten(input_shape=tf_model.output_shape[1:]))\n",
    "top_model.add(Dense(512, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(5, activation='softmax'))\n",
    "print (tf_model.summary())\n",
    "print(top_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the model on top of the convolutional base\n",
    "tf_model.add(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freezing the weights of all layers except top\n",
    "\n",
    "for layer in tf_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "#Using an Adam optimizer with lower learning rate\n",
    "adam1=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#sgd = optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "tf_model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = adam1,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model for 5 epochs\n",
    "\n",
    "#tensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)\n",
    "checkpoint_callback = ModelCheckpoint('./models/vgg_weights_frozen_pattern.hdf5', monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "tf_model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch = nb_train_samples,\n",
    "        nb_epoch = 5,\n",
    "        validation_data = validation_generator,\n",
    "        nb_val_samples = nb_validation_samples,\n",
    "        verbose = 1,\n",
    "        initial_epoch = 0,\n",
    "        callbacks=[checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = np.array([])\n",
    "losses = np.array([])\n",
    "\n",
    "i=0\n",
    "for X_batch, Y_batch in validation_generator:\n",
    "    loss, accuracy = tf_model.evaluate(X_batch, Y_batch, verbose=0)\n",
    "    losses = np.append(losses, loss)\n",
    "    accuracies = np.append(accuracies, accuracy)\n",
    "    i += 1\n",
    "    if i == 20:\n",
    "       break\n",
    "       \n",
    "print(\"Validation: accuracy = %f  ;  loss = %f\" % (np.mean(accuracies), np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch = nb_train_samples,\n",
    "        nb_epoch = 13,\n",
    "        validation_data = validation_generator,\n",
    "        nb_val_samples = nb_validation_samples,\n",
    "        verbose = 1,\n",
    "        initial_epoch = 10,\n",
    "        callbacks=[checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_part = {\n",
    "    0: 'FullSleeve',\n",
    "    1: 'HalfSleeve',\n",
    "    2: 'Sleeveless'}\n",
    "class_pattern = {\n",
    "    0: 'Checked',\n",
    "    1: 'Floral',\n",
    "    2: 'Graphic',\n",
    "    3: 'Plain',\n",
    "    4: 'Striped'}\n",
    "class_fabric = {\n",
    "    0: 'Cotton',\n",
    "    1: 'Crochet',\n",
    "    2: 'Denim',\n",
    "    3: 'Silk',\n",
    "    4: 'Wool'}\n",
    "class_color = {\n",
    "    0: 'Black',\n",
    "    1: 'Blue',\n",
    "    2: 'Green',\n",
    "    3: 'Red',\n",
    "    4: 'White'}\n",
    "class_style = {\n",
    "    0: 'Casual',\n",
    "    1: 'Formal',\n",
    "    2: 'Party',\n",
    "    3: 'Summer',\n",
    "    4: 'Winter'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(X):\n",
    "    im = X\n",
    "    plt.imshow(im)\n",
    "    \n",
    "    plt.axis('on')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150\n",
    "\n",
    "imagelist = []\n",
    "# top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "image_data_dir = 'images/'\n",
    "#chosenOnes = sorted(os.listdir(train_data_dir))\n",
    "count = 0\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "data1_generator = test_datagen.flow_from_directory(\n",
    "        image_data_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=1,\n",
    "        class_mode=None,\n",
    "        shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the images array\n",
    "nb_data_samples = 9234\n",
    "c=0\n",
    "images_valid=[]\n",
    "for X_batch in data1_generator:\n",
    "    c+=1\n",
    "    if (c>nb_data_samples):\n",
    "        break\n",
    "    images_valid.append(X_batch[0,:,:,:])\n",
    "    \n",
    "\n",
    "data_images=np.asarray(images_valid)\n",
    "print (data_images.shape)\n",
    "#np.save(\"last_resort.npy\",np.asarray(imagelist,dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_model = load_model('./models/model_pattern_final.hdf5')\n",
    "fabric_model = load_model('./models/model_fabric_final.hdf5')\n",
    "color_model = load_model('./models/model_color_final.hdf5')\n",
    "style_model = load_model('./models/model_style_final.hdf5')\n",
    "part_model = load_model('./models/model_part_final.hdf5')\n",
    "#part_model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern=pattern_model.predict(data_images)\n",
    "fabric=fabric_model.predict(data_images)\n",
    "color=color_model.predict(data_images)\n",
    "style=style_model.predict(data_images)\n",
    "part=part_model.predict(data_images)\n",
    "print (\"Pattern : \" , pattern.shape)\n",
    "print (\"fabric : \" , fabric.shape)\n",
    "print (\"color : \" , color.shape)\n",
    "print (\"Style : \" , style.shape) \n",
    "print (\"Part : \" , part.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10,15):\n",
    "    \n",
    "    #show_sample(data_images[i])\n",
    "    print (\"Pattern : \" , class_pattern[np.argmax(pattern[i])])\n",
    "    print (\"Fabric : \" , class_fabric[np.argmax(fabric[i])])\n",
    "    print (\"Color : \" , class_color[np.argmax(color[i])])\n",
    "    print (\"Style : \" , class_style[np.argmax(style[i])])\n",
    "    print (\"Part : \" , class_part[np.argmax(part[i])])\n",
    "    show_sample(data_images[i])\n",
    "    print (\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list=[]\n",
    "for i in range(len(data_images)):\n",
    "    vals=np.zeros(5)\n",
    "    vals[0] = np.argmax(pattern[i])\n",
    "    vals[1] = np.argmax(fabric[i])\n",
    "    vals[2] = np.argmax(color[i])\n",
    "    vals[3] = np.argmax(style[i])\n",
    "    vals[4] = np.argmax(part[i])\n",
    "    feature_list.append(vals)\n",
    "    \n",
    "print (feature_list[3])\n",
    "feature_data = np.asarray(feature_list)\n",
    "print (feature_data.shape)\n",
    "#np.save(\"db_images.npy\",data_images)\n",
    "#np.save(\"db_features.npy\",feature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input_dir = 'input/'\n",
    "inpdata_generator = test_datagen.flow_from_directory(\n",
    "        image_input_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=1,\n",
    "        class_mode=None,\n",
    "        shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_input_samples = 2\n",
    "c=0\n",
    "images_input=[]\n",
    "for X_batch in inpdata_generator:\n",
    "    c+=1\n",
    "    if (c>nb_input_samples):\n",
    "        break\n",
    "    images_input.append(X_batch[0,:,:,:])\n",
    "    \n",
    "\n",
    "data_images_inp=np.asarray(images_input)\n",
    "print (data_images_inp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_pattern=pattern_model.predict(data_images_inp)\n",
    "inp_fabric=fabric_model.predict(data_images_inp)\n",
    "inp_color=color_model.predict(data_images_inp)\n",
    "inp_style=style_model.predict(data_images_inp)\n",
    "inp_part=part_model.predict(data_images_inp)\n",
    "print (\"Pattern : \" , inp_pattern.shape)\n",
    "print (\"Fabric : \" , inp_fabric.shape)\n",
    "print (\"Color : \" , inp_color.shape)\n",
    "print (\"Style : \" , inp_style.shape) \n",
    "print (\"Part : \" , inp_part.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(data_images_inp)):\n",
    "    print (\"Pattern : \" , class_pattern[np.argmax(pattern[i])])\n",
    "    print (\"Fabric : \" , class_fabric[np.argmax(fabric[i])])\n",
    "    print (\"Color : \" , class_color[np.argmax(color[i])])\n",
    "    print (\"Style : \" , class_style[np.argmax(style[i])])\n",
    "    print (\"Part : \" , class_part[np.argmax(part[i])])\n",
    "    show_sample(data_images_inp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_feature_list=[]\n",
    "for i in range(len(data_images_inp)):\n",
    "    vals=np.zeros(5)\n",
    "    vals[0] = np.argmax(inp_pattern[i])\n",
    "    vals[1] = np.argmax(inp_fabric[i])\n",
    "    vals[2] = np.argmax(inp_color[i])\n",
    "    vals[3] = np.argmax(inp_style[i])\n",
    "    vals[3] = np.argmax(inp_part[i])\n",
    "    inp_feature_list.append(vals)\n",
    "    \n",
    "inp_feature_data = np.asarray(inp_feature_list)\n",
    "print (inp_feature_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(feature_data,inp_feature_data):\n",
    "    num_samp=inp_feature_data.size\n",
    "#     print (num_samp)\n",
    "    sim_score={}\n",
    "    for i in range(len(feature_data)):\n",
    "        score=0\n",
    "#         show_sample(data_images[i])\n",
    "#         print(feature_data[i])\n",
    "        score_m= inp_feature_data - feature_data[i]\n",
    "#         print (score_m)\n",
    "        score = num_samp-np.count_nonzero(score_m)\n",
    "        sim_score[i]=score\n",
    "#         print (score)\n",
    "    \n",
    "    return sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities=similarity(feature_data,inp_feature_data)\n",
    "sorted_similarities = sorted(similarities.items(), key=operator.itemgetter(1),reverse=True)\n",
    "#print (sorted_similarities)\n",
    "num_reco=30\n",
    "num_data=feature_data.size\n",
    "for i in range(num_reco):\n",
    "    ind = sorted_similarities[i][0]\n",
    "    print(\"Score : \", sorted_similarities[i][1])\n",
    "    show_sample(data_images[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
